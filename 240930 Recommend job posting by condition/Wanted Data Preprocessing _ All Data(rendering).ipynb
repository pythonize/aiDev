{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "580e6401",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "642aefdf",
   "metadata": {},
   "source": [
    "주요 어휘 추출 전처리 후 페이지 추천 기능 적용"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24c3f751",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "511644ac",
   "metadata": {},
   "source": [
    "1. 전처리 코드 완성(디버깅 포함, 워드클라우드 생성)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bb62937",
   "metadata": {},
   "source": [
    "※ 라이브러리 및 프레임워크 필요시 설치"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8567a976",
   "metadata": {},
   "source": [
    "!pip install konlpy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2c3fc79",
   "metadata": {},
   "source": [
    "!pip install JPype1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1e6da02",
   "metadata": {},
   "source": [
    "!pip install wordcloud matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eec644e3",
   "metadata": {},
   "source": [
    "!pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51628283",
   "metadata": {},
   "source": [
    "!pip install --upgrade Pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7915cce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from konlpy.tag import Okt\n",
    "import re\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f571823d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 로드\n",
    "df = pd.read_csv(\"data/wanted_crawling_all_data.csv\", index_col=None, \n",
    "                 parse_dates=['Title', 'URL'], encoding='cp949')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74c7fd47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 불용어 리스트를 파일에서 읽어오기\n",
    "with open('stopwords-ko.txt', 'r', encoding='utf-8') as file:\n",
    "    stopwords = file.read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67cf61db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 형태소 분석기 초기화\n",
    "okt = Okt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e987731e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전처리 함수 정의 (명사 추출 및 불용어 제거, 영어 포함)\n",
    "def preprocess_text(text, okt):\n",
    "    if isinstance(text, str):\n",
    "        text = text.lower()  # 소문자로 변환 (영어에 유용)\n",
    "        text = re.sub(r'\\d+', '', text)  # 숫자 제거\n",
    "        text = re.sub(r'[^\\w\\s]', '', text)  # 특수 문자 제거\n",
    "        # 명사 추출\n",
    "        nouns = okt.nouns(text)\n",
    "        # 명사와 함께 영어 단어도 추출하기 위해 영어 필터링 추가\n",
    "        english_words = re.findall(r'\\b[a-zA-Z]+\\b', text)  # 영어 단어 추출\n",
    "        # 불용어 제거 및 단어 필터링\n",
    "        filtered_nouns = [noun for noun in nouns if noun not in stopwords and len(noun) > 1]\n",
    "        filtered_english = [word for word in english_words if word not in stopwords]\n",
    "        # 한국어 명사와 영어 단어를 결합하여 반환\n",
    "        return ' '.join(filtered_nouns + filtered_english)\n",
    "    return ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34bf55d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF-IDF 기반 중요 단어 추출 함수\n",
    "def get_important_words(column_text, n=50):\n",
    "    vectorizer = TfidfVectorizer(max_features=n, max_df=0.85, min_df=1) \n",
    "    X = vectorizer.fit_transform(column_text)\n",
    "    if X.shape[0] == 0:  # 문서가 없는 경우\n",
    "        return []\n",
    "    feature_names = vectorizer.get_feature_names_out()\n",
    "    tfidf_scores = X.toarray().sum(axis=0)\n",
    "    word_score_pairs = sorted(zip(feature_names, tfidf_scores), key=lambda x: x[1], reverse=True)\n",
    "    return word_score_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63756b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 각 열에 대해 전처리 및 TF-IDF 기반 중요 단어 추출 (URL 칼럼 제외)\n",
    "important_words_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03b73dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in df.columns:\n",
    "    # 해당 칼럼은 처리하지 않음\n",
    "    if column in ['Title', 'Company', 'Career', 'Deadline', 'Location', 'Duty', 'URL']:\n",
    "        continue\n",
    "    if df[column].dtype == 'object':  # 문자열 데이터에 대해서만 처리\n",
    "        # 전처리 및 명사 추출\n",
    "        df[column] = df[column].apply(preprocess_text)\n",
    "        column_text = df[column].dropna().tolist()  # NaN 값 제거 및 리스트로 변환\n",
    "        \n",
    "        # 텍스트 샘플 출력 (디버깅용)\n",
    "        print(f\"Column: {column}\")\n",
    "        print(\"Sample Texts:\")\n",
    "        print(column_text[:5])  # 상위 5개 텍스트 샘플 출력\n",
    "        \n",
    "        if len(column_text) > 0:  # 데이터가 있는 경우에만 처리\n",
    "            # TF-IDF 기반 중요 단어 추출\n",
    "            important_words = get_important_words(column_text, n=50)\n",
    "            if important_words:  # 중요 단어가 추출된 경우에만 처리\n",
    "                important_words_dict[column] = important_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1bb1627",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 각 칼럼별 중요 단어를 CSV 파일로 저장\n",
    "for column, words in important_words_dict.items():\n",
    "    df_words = pd.DataFrame(words, columns=['Word', 'Score'])\n",
    "    df_words.to_csv(f'{column}_important_words.csv', index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad67cc2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전처리된 텍스트 확인 (디버깅용)\n",
    "for column in df.columns:\n",
    "    if column in important_words_dict:\n",
    "        print(f\"Column: {column}\")\n",
    "        print(df[column].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "965c943a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전처리된 데이터프레임 저장\n",
    "df.to_csv('preprocessed_data_all.csv', index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c15748",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 워드클라우드 생성 및 저장 함수\n",
    "def create_wordcloud(words, column_name):\n",
    "    word_freq = dict(words)  # 중요 단어와 점수를 딕셔너리 형태로 변환\n",
    "    wordcloud = WordCloud(font_path='C:/Windows/Fonts/malgun.ttf',  # 한글 폰트 경로\n",
    "                          width=800, height=400, \n",
    "                          background_color='white').generate_from_frequencies(word_freq)\n",
    "    \n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.imshow(wordcloud, interpolation='bilinear')\n",
    "    plt.axis('off')\n",
    "    plt.title(f'Word Cloud for {column_name}')\n",
    "    plt.savefig(f'{column_name}_wordcloud.png', format='png')\n",
    "    plt.show()\n",
    "\n",
    "# 각 칼럼별 워드클라우드 생성 및 저장\n",
    "for column, words in important_words_dict.items():\n",
    "    create_wordcloud(words, column)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb8f1887",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6151e907",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dfba742",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23f448ce",
   "metadata": {},
   "source": [
    "2. 데이터 전처리 후 추천기능 적용(통합검색 추천)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5ce160a",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed3c3d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "542a7e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 로드\n",
    "df = pd.read_csv(\"data/wanted_crawling_all_data.csv\", index_col=None, encoding='cp949')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e146c22e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 불용어 리스트를 파일에서 읽어오기\n",
    "with open('stopwords-ko.txt', 'r', encoding='utf-8') as file:\n",
    "    stopwords = file.read().splitlines()\n",
    "\n",
    "# 전처리 함수 정의 (명사 추출 및 불용어 제거, 영어 포함)\n",
    "def preprocess_text(text, okt):\n",
    "    if isinstance(text, str):\n",
    "        text = text.lower()  # 소문자로 변환 (영어에 유용)\n",
    "        text = re.sub(r'\\d+', '', text)  # 숫자 제거\n",
    "        text = re.sub(r'[^\\w\\s]', '', text)  # 특수 문자 제거\n",
    "        # 명사 추출\n",
    "        nouns = okt.nouns(text)\n",
    "        # 명사와 함께 영어 단어도 추출하기 위해 영어 필터링 추가\n",
    "        english_words = re.findall(r'\\b[a-zA-Z]+\\b', text)  # 영어 단어 추출\n",
    "        # 불용어 제거 및 단어 필터링\n",
    "        filtered_nouns = [noun for noun in nouns if noun not in stopwords and len(noun) > 1]\n",
    "        filtered_english = [word for word in english_words if word not in stopwords]\n",
    "        # 한국어 명사와 영어 단어를 결합하여 반환\n",
    "        return ' '.join(filtered_nouns + filtered_english)\n",
    "    return ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8426fc02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 형태소 분석기 초기화\n",
    "from konlpy.tag import Okt\n",
    "okt = Okt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e87134f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사용자의 조건을 입력받아 유사한 채용 공고 추천하는 함수\n",
    "def recommend_jobs(user_query, df, okt, top_n=5):\n",
    "    # NaN 값을 빈 문자열로 대체\n",
    "    df.fillna('', inplace=True)\n",
    "    # 여러 칼럼을 전처리 (Title, Company, 주요 업무, 기술 스택 등 필요한 칼럼 추가)\n",
    "    df['preprocessed_title'] = df['Title']\n",
    "    df['preprocessed_company'] = df['Company']\n",
    "    df['preprocessed_career'] = df['Career']\n",
    "    df['preprocessed_work'] = df['Work'].apply(lambda x: preprocess_text(x, okt))\n",
    "    df['preprocessed_qualification'] = df['Qualification'].apply(lambda x: preprocess_text(x, okt))\n",
    "    df['preprocessed_addition'] = df['Addition'].apply(lambda x: preprocess_text(x, okt))\n",
    "    df['preprocessed_welfare'] = df['Welfare'].apply(lambda x: preprocess_text(x, okt))\n",
    "    df['preprocessed_skill'] = df['Skill']\n",
    "    df['preprocessed_tag'] = df['Tag']\n",
    "    df['preprocessed_deadline'] = df['Deadline']\n",
    "    df['preprocessed_location'] = df['Location']\n",
    "    df['preprocessed_duty'] = df['Duty']\n",
    "    \n",
    "    # 사용자가 입력한 질의를 전처리\n",
    "    query_preprocessed = preprocess_text(user_query, okt)\n",
    "\n",
    "    # TF-IDF 벡터화\n",
    "    vectorizer = TfidfVectorizer()\n",
    "\n",
    "    # 여러 칼럼을 하나의 텍스트로 결합 (공백을 추가하여 결합)\n",
    "    df['combined_text'] = df['preprocessed_title'] + ' ' + df['preprocessed_company'] + ' ' + df['preprocessed_career'] + ' ' + df['preprocessed_work'] + ' ' + df['preprocessed_qualification'] + ' ' + df['preprocessed_addition'] + ' ' + df['preprocessed_welfare'] + ' ' + df['preprocessed_skill'] + ' ' + df['preprocessed_tag'] + ' ' + df['preprocessed_deadline'] + ' ' + df['preprocessed_location'] + ' ' + df['preprocessed_duty']\n",
    "    combined_matrix = vectorizer.fit_transform(df['combined_text'])\n",
    "    \n",
    "    # 사용자의 질의를 벡터화\n",
    "    query_vector = vectorizer.transform([query_preprocessed])\n",
    "\n",
    "    # 코사인 유사도 계산\n",
    "    similarity_scores = cosine_similarity(query_vector, combined_matrix).flatten()\n",
    "\n",
    "    # 유사도 순으로 상위 N개의 인덱스 추출\n",
    "    top_indices = similarity_scores.argsort()[-top_n:][::-1]\n",
    "\n",
    "    # 상위 N개의 회사, 제목, URL을 추천\n",
    "    recommendations = df[['Title', 'Company', 'URL']].iloc[top_indices]\n",
    "    return recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4420ec7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사용자가 선택한 조건\n",
    "user_query = \"서울에 있는 신입 뽑는 IT 기업 추천해줘\"\n",
    "\n",
    "# 채용 공고 추천\n",
    "recommended_jobs = recommend_jobs(user_query, df, okt, top_n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da00f8ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 추천 결과 출력\n",
    "print(recommended_jobs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2509351c",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4499cbeb",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ab62b2f",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3804eae0",
   "metadata": {},
   "source": [
    "3. 문답 형식에 따른 채용공고 추천 코드(조건에 따른 검색 추천)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07fb4e2c",
   "metadata": {},
   "source": [
    " 1) 구글 맵스를 활용한 근무지 위치 정확한 주소로 변경"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44553ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install googlemaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea1f47dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import googlemaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da80525a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import re\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a624765c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 로드\n",
    "df = pd.read_csv(\"data/wanted_crawling_all_data.csv\", index_col=None, encoding='cp949')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c48f539",
   "metadata": {},
   "outputs": [],
   "source": [
    "gmaps_key = 'AIzaSyBWUgRUl_18YTfLl4hXjNPfNBYRh-HwF40'\n",
    "gmaps = googlemaps.Client(key = gmaps_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c76083b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_location(location):\n",
    "    tmp = gmaps.geocode(location, language='ko')\n",
    "    if tmp:\n",
    "        return tmp[0].get('formatted_address')\n",
    "    return location\n",
    "\n",
    "# tqdm으로 진행 상황 표시\n",
    "with ThreadPoolExecutor(max_workers=10) as executor:\n",
    "    # tqdm을 사용하여 진행 상황 표시\n",
    "    df['Location'] = list(tqdm(executor.map(fetch_location, df['Location']), total=len(df['Location'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "411a9220",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Location']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdb7e8dc",
   "metadata": {},
   "source": [
    "# 'Location' 칼럼 정확한 주소로 변경\n",
    "for i in range(len(df['Location'])):\n",
    "    location = df['Location'][i]\n",
    "    \n",
    "    # Google Maps 주소 변환\n",
    "    tmp = gmaps.geocode(location, language='ko')\n",
    "    \n",
    "    #'formatted_address'로 Location 값 업데이트\n",
    "    if tmp:  # tmp 리스트가 존재할 시\n",
    "        df['Location'][i] = tmp[0].get('formatted_address')\n",
    "\n",
    "# 결과 확인\n",
    "print(df['Location'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87df89b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전처리된 데이터프레임 저장\n",
    "df.to_csv('preprocessed_locationdata_all.csv', index=False, encoding='cp949')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "908a326e",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac692111",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc517e82",
   "metadata": {},
   "source": [
    "2) 조건에 따른 검색기능"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71bdf45f",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "440b017a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 로드\n",
    "df = pd.read_csv(\"data/preprocessed_locationdata_all.csv\", index_col=None, encoding='cp949')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3ab881b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 불용어 리스트를 파일에서 읽어오기\n",
    "with open('stopwords-ko.txt', 'r', encoding='utf-8') as file:\n",
    "    stopwords = file.read().splitlines()\n",
    "\n",
    "# 전처리 함수 정의 (명사 추출 및 불용어 제거, 영어 포함)\n",
    "def preprocess_text(text, okt):\n",
    "    if isinstance(text, str):\n",
    "        text = text.lower()  # 소문자로 변환\n",
    "        text = re.sub(r'\\d+', '', text)  # 숫자 제거\n",
    "        text = re.sub(r'[^\\w\\s]', '', text)  # 특수 문자 제거\n",
    "        # 명사 추출\n",
    "        nouns = okt.nouns(text)\n",
    "        # 영어 단어 추출\n",
    "        english_words = re.findall(r'\\b[a-zA-Z]+\\b', text)\n",
    "        # 불용어 제거 및 단어 필터링\n",
    "        filtered_nouns = [noun for noun in nouns if noun not in stopwords and len(noun) > 1]\n",
    "        filtered_english = [word for word in english_words if word not in stopwords]\n",
    "        # 한국어 명사와 영어 단어를 결합하여 반환\n",
    "        return ' '.join(filtered_nouns + filtered_english)\n",
    "    return ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a95cdef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 형태소 분석기 초기화\n",
    "from konlpy.tag import Okt\n",
    "okt = Okt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f73eee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사용자 검색어 입력\n",
    "def ask_question(question):\n",
    "    response = input(question + \" \")\n",
    "    return response\n",
    "\n",
    "# 조건에 따른 필터링\n",
    "def filter_jobs_by_criteria(df, location=None, duty=None, career=None):\n",
    "    filtered_df = df.copy()\n",
    "    \n",
    "    # 조건에 따라 데이터 필터링\n",
    "    if location and not pd.isna(location):\n",
    "        filtered_df = filtered_df[filtered_df['Location'].str.strip().str.contains(location.strip(), case=False, na=False)]\n",
    "    if duty and not pd.isna(duty):\n",
    "        filtered_df = filtered_df[filtered_df['Duty'].str.strip().str.contains(duty.strip(), case=False, na=False)]\n",
    "    if career and not pd.isna(career):\n",
    "        filtered_df = filtered_df[filtered_df['Career'].str.strip().str.contains(career.strip(), case=False, na=False)]\n",
    "    \n",
    "    return filtered_df\n",
    "\n",
    "# 유사 채용 공고 추천 함수 (문답에 따른 범위 좁히기)\n",
    "def recommend_interactively(df, okt):\n",
    "    # 사용자의 선택 조건을 순차적으로 입력\n",
    "    location = ask_question(\"선호하는 지역을 말씀해주세요:\")\n",
    "    duty = ask_question(\"선호하는 직무를 말씀해주세요:\")\n",
    "    career = ask_question(\"경력에 대한 조건을 말씀해주세요:\")\n",
    "\n",
    "    # 필터링된 데이터프레임\n",
    "    filtered_df = filter_jobs_by_criteria(df, location, duty, career)\n",
    "    \n",
    "    if filtered_df.empty:\n",
    "        print(\"해당 조건에 맞는 채용 공고가 없습니다.\")\n",
    "        return\n",
    "    \n",
    "    # 전처리 (필요한 칼럼에 대한 전처리 수행)\n",
    "    filtered_df['preprocessed_work'] = filtered_df['Work'].apply(lambda x: preprocess_text(x, okt))\n",
    "    filtered_df['preprocessed_qualification'] = filtered_df['Qualification'].apply(lambda x: preprocess_text(x, okt))\n",
    "    filtered_df['preprocessed_addition'] = filtered_df['Addition'].apply(lambda x: preprocess_text(x, okt))\n",
    "    filtered_df['preprocessed_welfare'] = filtered_df['Welfare'].apply(lambda x: preprocess_text(x, okt))\n",
    "\n",
    "    # 사용자 질의를 입력받고 전처리\n",
    "    user_query = ask_question(\"검색하려는 키워드를 입력해주세요:\")\n",
    "    query_preprocessed = preprocess_text(user_query, okt)\n",
    "\n",
    "    # TF-IDF 벡터화\n",
    "    vectorizer = TfidfVectorizer()\n",
    "\n",
    "    # 여러 칼럼을 결합하여 벡터화\n",
    "    filtered_df['combined_text'] = (\n",
    "        filtered_df['Title'].fillna('') + ' ' +\n",
    "        filtered_df['Company'].fillna('') + ' ' +\n",
    "        filtered_df['preprocessed_work'].fillna('') + ' ' +\n",
    "        filtered_df['preprocessed_qualification'].fillna('') + ' ' +\n",
    "        filtered_df['preprocessed_addition'].fillna('') + ' ' +\n",
    "        filtered_df['preprocessed_welfare'].fillna('') + ' ' +\n",
    "        filtered_df['Skill'].fillna('') + ' ' +\n",
    "        filtered_df['Tag'].fillna('') + ' ' +\n",
    "        filtered_df['Deadline'].fillna('') + ' ' +\n",
    "        filtered_df['Location'].fillna('') + ' ' +\n",
    "        filtered_df['Duty'].fillna('')\n",
    "    )\n",
    "\n",
    "    # TfidfVectorizer를 적용\n",
    "    combined_matrix = vectorizer.fit_transform(filtered_df['combined_text'])\n",
    "\n",
    "    # 사용자 질의를 벡터화\n",
    "    query_vector = vectorizer.transform([query_preprocessed])\n",
    "\n",
    "    # 코사인 유사도 계산\n",
    "    similarity_scores = cosine_similarity(query_vector, combined_matrix).flatten()\n",
    "\n",
    "    # 유사도 순으로 상위 5개의 인덱스 추출\n",
    "    top_indices = similarity_scores.argsort()[-5:][::-1]\n",
    "\n",
    "    # 상위 5개의 회사, 제목, URL을 추천\n",
    "    recommendations = filtered_df[['Title', 'Company', 'URL']].iloc[top_indices]\n",
    "    \n",
    "    print(\"추천 결과:\")\n",
    "    print(recommendations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fd53473",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 채용 공고 추천 시스템 실행\n",
    "recommend_interactively(df, okt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7bac970",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0df4cdd",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3076db68",
   "metadata": {},
   "source": [
    "3) 조건에 따른 채용공고 추천(오타 가능) - 정확도 떨어짐"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1d716b9",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "828ddbbd",
   "metadata": {},
   "source": [
    "!pip install fuzzywuzzy[speedup]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "341506bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from konlpy.tag import Okt\n",
    "from fuzzywuzzy import process, fuzz\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c8c6e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 로드\n",
    "df = pd.read_csv(\"data/preprocessed_locationdata_all.csv\", index_col=None, encoding='cp949')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e08cffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 불용어 리스트를 파일에서 읽어오기\n",
    "with open('stopwords-ko.txt', 'r', encoding='utf-8') as file:\n",
    "    stopwords = file.read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6572f76b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전처리 함수 정의 (명사 추출 및 불용어 제거, 영어 포함)\n",
    "def preprocess_text(text, okt):\n",
    "    if isinstance(text, str):\n",
    "        text = text.lower()  # 소문자로 변환\n",
    "        text = re.sub(r'\\d+', '', text)  # 숫자 제거\n",
    "        text = re.sub(r'[^\\w\\s]', '', text)  # 특수 문자 제거\n",
    "        # 명사 추출\n",
    "        nouns = okt.nouns(text)\n",
    "        # 영어 단어 추출\n",
    "        english_words = re.findall(r'\\b[a-zA-Z]+\\b', text)\n",
    "        # 불용어 제거 및 단어 필터링\n",
    "        filtered_nouns = [noun for noun in nouns if noun not in stopwords and len(noun) > 1]\n",
    "        filtered_english = [word for word in english_words if word not in stopwords]\n",
    "        # 한국어 명사와 영어 단어를 결합하여 반환\n",
    "        return ' '.join(filtered_nouns + filtered_english)\n",
    "    return ''\n",
    "\n",
    "# 유사한 텍스트 찾기 함수 (fuzzy 매칭)\n",
    "def fuzzy_match(input_text, choices, threshold=70):\n",
    "    if not input_text or pd.isna(input_text):\n",
    "        return None\n",
    "    # 입력 텍스트와 choices 리스트에서 가장 유사한 텍스트 추출\n",
    "    best_match = process.extractOne(input_text.strip(), choices, score_cutoff=threshold)\n",
    "    if best_match:\n",
    "        return best_match[0]  # best_match는 (matched_text, score)의 튜플로 반환됨\n",
    "    return None\n",
    "\n",
    "# 조건에 따른 필터링 (fuzzy 매칭 적용)\n",
    "def filter_jobs_by_criteria(df, location=None, duty=None, career=None):\n",
    "    filtered_df = df.copy()\n",
    "    \n",
    "    # Location에 따른 fuzzy 필터링\n",
    "    if location and not pd.isna(location):\n",
    "        location_choices = filtered_df['Location'].dropna().unique().tolist()\n",
    "        matched_location = fuzzy_match(location, location_choices)\n",
    "        if matched_location:\n",
    "            filtered_df = filtered_df[filtered_df['Location'].str.contains(matched_location, case=False, na=False)]\n",
    "\n",
    "    # Duty에 따른 fuzzy 필터링\n",
    "    if duty and not pd.isna(duty):\n",
    "        duty_choices = filtered_df['Duty'].dropna().unique().tolist()\n",
    "        matched_duty = fuzzy_match(duty, duty_choices)\n",
    "        if matched_duty:\n",
    "            filtered_df = filtered_df[filtered_df['Duty'].str.contains(matched_duty, case=False, na=False)]\n",
    "\n",
    "    # Career에 따른 fuzzy 필터링\n",
    "    if career and not pd.isna(career):\n",
    "        career_choices = filtered_df['Career'].dropna().unique().tolist()\n",
    "        matched_career = fuzzy_match(career, career_choices)\n",
    "        if matched_career:\n",
    "            filtered_df = filtered_df[filtered_df['Career'].str.contains(matched_career, case=False, na=False)]\n",
    "    \n",
    "    return filtered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62619318",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사용자 검색어 입력\n",
    "def ask_question(question):\n",
    "    response = input(question + \" \")\n",
    "    return response\n",
    "\n",
    "# 유사 채용 공고 추천 함수 (문답에 따른 범위 좁히기)\n",
    "def recommend_interactively(df, okt):\n",
    "    # 사용자의 선택 조건을 순차적으로 입력\n",
    "    location = ask_question(\"선호하는 지역을 말씀해주세요:\")\n",
    "    duty = ask_question(\"선호하는 직무를 말씀해주세요:\")\n",
    "    career = ask_question(\"경력에 대한 조건을 말씀해주세요:\")\n",
    "\n",
    "    # 필터링된 데이터프레임\n",
    "    filtered_df = filter_jobs_by_criteria(df, location, duty, career)\n",
    "    \n",
    "    if filtered_df.empty:\n",
    "        print(\"해당 조건에 맞는 채용 공고가 없습니다.\")\n",
    "        return\n",
    "    \n",
    "    # 전처리 (필요한 칼럼에 대한 전처리 수행)\n",
    "    filtered_df['preprocessed_work'] = filtered_df['Work'].apply(lambda x: preprocess_text(x, okt))\n",
    "    filtered_df['preprocessed_qualification'] = filtered_df['Qualification'].apply(lambda x: preprocess_text(x, okt))\n",
    "    filtered_df['preprocessed_addition'] = filtered_df['Addition'].apply(lambda x: preprocess_text(x, okt))\n",
    "    filtered_df['preprocessed_welfare'] = filtered_df['Welfare'].apply(lambda x: preprocess_text(x, okt))\n",
    "\n",
    "    # 사용자 질의를 입력받고 전처리 없이 저장\n",
    "    user_query = ask_question(\"검색하려는 키워드를 입력해주세요:\")\n",
    "    \n",
    "    # TF-IDF 벡터화\n",
    "    vectorizer = TfidfVectorizer()\n",
    "\n",
    "    # 여러 칼럼을 결합하여 벡터화\n",
    "    filtered_df['combined_text'] = (\n",
    "        filtered_df['Title'].fillna('') + ' ' +\n",
    "        filtered_df['Company'].fillna('') + ' ' +\n",
    "        filtered_df['preprocessed_work'].fillna('') + ' ' +\n",
    "        filtered_df['preprocessed_qualification'].fillna('') + ' ' +\n",
    "        filtered_df['preprocessed_addition'].fillna('') + ' ' +\n",
    "        filtered_df['preprocessed_welfare'].fillna('') + ' ' +\n",
    "        filtered_df['Skill'].fillna('') + ' ' +\n",
    "        filtered_df['Tag'].fillna('') + ' ' +\n",
    "        filtered_df['Deadline'].fillna('') + ' ' +\n",
    "        filtered_df['Location'].fillna('') + ' ' +\n",
    "        filtered_df['Duty'].fillna('')\n",
    "    )\n",
    "\n",
    "    # TfidfVectorizer를 적용\n",
    "    combined_matrix = vectorizer.fit_transform(filtered_df['combined_text'])\n",
    "\n",
    "    # 사용자 질의를 벡터화\n",
    "    query_vector = vectorizer.transform([user_query])  # 전처리 없이 사용자 질의 사용\n",
    "\n",
    "    # 코사인 유사도 계산\n",
    "    similarity_scores = cosine_similarity(query_vector, combined_matrix).flatten()\n",
    "\n",
    "    # 유사도 순으로 상위 10개의 인덱스 추출\n",
    "    top_indices = similarity_scores.argsort()[-10:][::-1]\n",
    "\n",
    "    # 상위 10개의 회사, 제목, URL을 추천\n",
    "    recommendations = filtered_df[['Title', 'Company', 'URL', 'combined_text']].iloc[top_indices]\n",
    "\n",
    "    # fuzzy matching을 사용하여 유사한 키워드를 찾기\n",
    "    fuzzy_recommendations = []\n",
    "    for idx in top_indices:\n",
    "        row = recommendations.iloc[top_indices.tolist().index(idx)]  # 수정된 부분\n",
    "        score = fuzz.partial_ratio(user_query, row['combined_text'])  # 전처리 없이 사용자 질의 사용\n",
    "        combined_score = (similarity_scores[idx] + score) / 2  # 코사인 유사도와 fuzzy 점수 결합\n",
    "        fuzzy_recommendations.append((row['Title'], row['Company'], row['URL'], combined_score))\n",
    "\n",
    "    # 유사도 점수를 기준으로 상위 5개 추출\n",
    "    fuzzy_recommendations = sorted(fuzzy_recommendations, key=lambda x: x[3], reverse=True)[:5]\n",
    "\n",
    "    # 추천 결과 출력\n",
    "    print(\"추천 결과:\")\n",
    "    for title, company, url, score in fuzzy_recommendations:\n",
    "        print(f\"회사: {company}, 제목: {title}, URL: {url}, 유사도: {score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3bdcf0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 채용 공고 추천 시스템 실행\n",
    "recommend_interactively(df, Okt())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65d7e9dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b23d188d",
   "metadata": {},
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
